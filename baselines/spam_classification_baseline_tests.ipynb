{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbDqM8XXuMbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from domain.text_vectorizers import ASCIIVectorizer, BoWVectorizer, BiLSTMVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTq1H0bAuMbe",
        "colab_type": "text"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj3sxqN7uMbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an5bTABhuMbg",
        "colab_type": "text"
      },
      "source": [
        "### 1. Spam Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0u6K5DiuMbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"data/spam_classify/train.csv\")\n",
        "test = pd.read_csv(\"data/spam_classify/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY3Ojf4JuMbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_texts, train_labels = list(train.v2), list(train.v1)\n",
        "test_texts, test_labels = list(test.v2), list(test.v1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJYSGEA0uMbl",
        "colab_type": "text"
      },
      "source": [
        "#### ASCII"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc9U_OdPuMbl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "b2f90706-7395-4833-e60d-c4bb0b0e1cec"
      },
      "source": [
        "model = LogisticRegression(random_state=0, solver='liblinear')\n",
        "for method in [\"mean\", \"first\"]:\n",
        "    print(f\"Agg method: {method}\")\n",
        "    vectorizer = ASCIIVectorizer(max_features=128, char_aggregator=method) \n",
        "    \n",
        "    X_train, y_train = vectorizer.transform(train_texts, train_labels)\n",
        "    X_test, y_test = vectorizer.transform(test_texts, test_labels)\n",
        "    \n",
        "    # Fit the model to training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make prediction using the trained model\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate\n",
        "    train_acc = accuracy_score(y_train, y_train_pred)\n",
        "    train_prec = precision_score(y_train, y_train_pred)\n",
        "    train_rec = recall_score(y_train, y_train_pred)\n",
        "    train_f1 = f1_score(y_train, y_train_pred)\n",
        "    \n",
        "    test_acc = accuracy_score(y_test, y_test_pred)\n",
        "    test_prec = precision_score(y_test, y_test_pred)\n",
        "    test_rec = recall_score(y_test, y_test_pred)\n",
        "    test_f1 = f1_score(y_test, y_test_pred)\n",
        "    \n",
        "    print(f\"Training accuracy: {train_acc:.3f}, \"\n",
        "          f\"Precison: {train_prec:.3f}, \"\n",
        "          f\"Recall: {train_rec:.3f}, \"\n",
        "          f\"F1 score: {train_f1:.3f}\")\n",
        "    print(f\"Test accuracy: {test_acc:.3f}, \"\n",
        "          f\"Precison: {test_prec:.3f}, \"\n",
        "          f\"Recall: {test_rec:.3f}, \"\n",
        "          f\"F1 score: {test_f1:.3f}\\n\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Agg method: mean\n",
            "Training accuracy: 0.867, Precison: 0.522, Recall: 0.179, F1 score: 0.267\n",
            "Test accuracy: 0.856, Precison: 0.373, Recall: 0.152, F1 score: 0.216\n",
            "\n",
            "Agg method: first\n",
            "Training accuracy: 0.868, Precison: 0.531, Recall: 0.198, F1 score: 0.288\n",
            "Test accuracy: 0.858, Precison: 0.377, Recall: 0.138, F1 score: 0.202\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEpTStbhuMbo",
        "colab_type": "text"
      },
      "source": [
        "#### BoW "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vmU9E15uMbp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "outputId": "61ff756a-340d-42b5-a0b3-c971071a1baf"
      },
      "source": [
        "model = LogisticRegression(random_state=0, solver='liblinear')\n",
        "for nf in [8, 16, 32, 64, 128, 256, 512, 1024, 2048]:\n",
        "    print(f\"Vocab size: {nf}\")\n",
        "    \n",
        "    vectorizer = BoWVectorizer(max_features=nf)\n",
        "    vectorizer.fit(train_texts)\n",
        "    \n",
        "    X_train, y_train = vectorizer.transform(train_texts, train_labels)\n",
        "    X_test, y_test = vectorizer.transform(test_texts, test_labels)\n",
        "\n",
        "    # Fit the model to training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make prediction using the trained model\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate\n",
        "    train_acc = accuracy_score(y_train, y_train_pred)\n",
        "    train_prec = precision_score(y_train, y_train_pred)\n",
        "    train_rec = recall_score(y_train, y_train_pred)\n",
        "    train_f1 = f1_score(y_train, y_train_pred)\n",
        "    \n",
        "    test_acc = accuracy_score(y_test, y_test_pred)\n",
        "    test_prec = precision_score(y_test, y_test_pred)\n",
        "    test_rec = recall_score(y_test, y_test_pred)\n",
        "    test_f1 = f1_score(y_test, y_test_pred)\n",
        "    \n",
        "    print(f\"Training accuracy: {train_acc:.3f}, \"\n",
        "          f\"Precison: {train_prec:.3f}, \"\n",
        "          f\"Recall: {train_rec:.3f}, \"\n",
        "          f\"F1 score: {train_f1:.3f}\")\n",
        "    print(f\"Test accuracy: {test_acc:.3f}, \"\n",
        "          f\"Precison: {test_prec:.3f}, \"\n",
        "          f\"Recall: {test_rec:.3f}, \"\n",
        "          f\"F1 score: {test_f1:.3f}\\n\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 8\n",
            "Training accuracy: 0.864, Precison: 0.441, Recall: 0.025, F1 score: 0.047\n",
            "Test accuracy: 0.873, Precison: 1.000, Recall: 0.028, F1 score: 0.054\n",
            "\n",
            "Vocab size: 16\n",
            "Training accuracy: 0.897, Precison: 0.738, Recall: 0.374, F1 score: 0.496\n",
            "Test accuracy: 0.905, Precison: 0.753, Recall: 0.400, F1 score: 0.523\n",
            "\n",
            "Vocab size: 32\n",
            "Training accuracy: 0.919, Precison: 0.774, Recall: 0.563, F1 score: 0.652\n",
            "Test accuracy: 0.922, Precison: 0.796, Recall: 0.538, F1 score: 0.642\n",
            "\n",
            "Vocab size: 64\n",
            "Training accuracy: 0.939, Precison: 0.849, Recall: 0.664, F1 score: 0.746\n",
            "Test accuracy: 0.935, Precison: 0.841, Recall: 0.621, F1 score: 0.714\n",
            "\n",
            "Vocab size: 128\n",
            "Training accuracy: 0.969, Precison: 0.946, Recall: 0.816, F1 score: 0.876\n",
            "Test accuracy: 0.956, Precison: 0.875, Recall: 0.772, F1 score: 0.821\n",
            "\n",
            "Vocab size: 256\n",
            "Training accuracy: 0.982, Precison: 0.980, Recall: 0.882, F1 score: 0.928\n",
            "Test accuracy: 0.973, Precison: 0.946, Recall: 0.841, F1 score: 0.891\n",
            "\n",
            "Vocab size: 512\n",
            "Training accuracy: 0.985, Precison: 0.993, Recall: 0.897, F1 score: 0.942\n",
            "Test accuracy: 0.978, Precison: 0.976, Recall: 0.848, F1 score: 0.908\n",
            "\n",
            "Vocab size: 1024\n",
            "Training accuracy: 0.990, Precison: 0.998, Recall: 0.927, F1 score: 0.961\n",
            "Test accuracy: 0.979, Precison: 0.977, Recall: 0.862, F1 score: 0.916\n",
            "\n",
            "Vocab size: 2048\n",
            "Training accuracy: 0.991, Precison: 0.998, Recall: 0.939, F1 score: 0.967\n",
            "Test accuracy: 0.979, Precison: 0.977, Recall: 0.862, F1 score: 0.916\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T5Yw6T1uMbr",
        "colab_type": "text"
      },
      "source": [
        "#### BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoaNNft6uMbs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "d0827b0d-8648-4e17-ac54-d607a9a39768"
      },
      "source": [
        "model = LogisticRegression(random_state=0, solver='liblinear')\n",
        "for vs in [10, 20, 50, 100, 200, 500, 1000, 2000]:    \n",
        "    vectorizer = BiLSTMVectorizer(vocab_size=vs)\n",
        "    \n",
        "    X_train, y_train = vectorizer.transform(train_texts, train_labels)\n",
        "    X_test, y_test = vectorizer.transform(test_texts, test_labels)\n",
        "\n",
        "    # Fit the model to training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make prediction using the trained model\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate\n",
        "    train_acc = accuracy_score(y_train, y_train_pred)\n",
        "    train_prec = precision_score(y_train, y_train_pred)\n",
        "    train_rec = recall_score(y_train, y_train_pred)\n",
        "    train_f1 = f1_score(y_train, y_train_pred)\n",
        "    \n",
        "    test_acc = accuracy_score(y_test, y_test_pred)\n",
        "    test_prec = precision_score(y_test, y_test_pred)\n",
        "    test_rec = recall_score(y_test, y_test_pred)\n",
        "    test_f1 = f1_score(y_test, y_test_pred)\n",
        "    \n",
        "    print(f\"Training accuracy: {train_acc:.3f}, \"\n",
        "          f\"Precison: {train_prec:.3f}, \"\n",
        "          f\"Recall: {train_rec:.3f}, \"\n",
        "          f\"F1 score: {train_f1:.3f}\")\n",
        "    print(f\"Test accuracy: {test_acc:.3f}, \"\n",
        "          f\"Precison: {test_prec:.3f}, \"\n",
        "          f\"Recall: {test_rec:.3f}, \"\n",
        "          f\"F1 score: {test_f1:.3f}\\n\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size : 10\n",
            "Training accuracy: 0.891, Precison: 0.764, Recall: 0.274, F1 score: 0.403\n",
            "Test accuracy: 0.880, Precison: 0.704, Recall: 0.131, F1 score: 0.221\n",
            "\n",
            "Vocab size : 20\n",
            "Training accuracy: 0.921, Precison: 0.838, Recall: 0.517, F1 score: 0.639\n",
            "Test accuracy: 0.895, Precison: 0.684, Recall: 0.359, F1 score: 0.471\n",
            "\n",
            "Vocab size : 50\n",
            "Training accuracy: 0.955, Precison: 0.929, Recall: 0.721, F1 score: 0.812\n",
            "Test accuracy: 0.936, Precison: 0.863, Recall: 0.607, F1 score: 0.713\n",
            "\n",
            "Vocab size : 100\n",
            "Training accuracy: 0.968, Precison: 0.947, Recall: 0.809, F1 score: 0.873\n",
            "Test accuracy: 0.946, Precison: 0.938, Recall: 0.628, F1 score: 0.752\n",
            "\n",
            "Vocab size : 200\n",
            "Training accuracy: 0.977, Precison: 0.970, Recall: 0.859, F1 score: 0.911\n",
            "Test accuracy: 0.952, Precison: 0.876, Recall: 0.731, F1 score: 0.797\n",
            "\n",
            "Vocab size : 500\n",
            "Training accuracy: 0.985, Precison: 0.980, Recall: 0.910, F1 score: 0.944\n",
            "Test accuracy: 0.963, Precison: 0.941, Recall: 0.766, F1 score: 0.844\n",
            "\n",
            "Vocab size : 1000\n",
            "Training accuracy: 0.986, Precison: 0.982, Recall: 0.912, F1 score: 0.946\n",
            "Test accuracy: 0.966, Precison: 0.957, Recall: 0.772, F1 score: 0.855\n",
            "\n",
            "Vocab size : 2000\n",
            "Training accuracy: 0.987, Precison: 0.982, Recall: 0.917, F1 score: 0.948\n",
            "Test accuracy: 0.978, Precison: 0.962, Recall: 0.862, F1 score: 0.909\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U7J1oX4uMbu",
        "colab_type": "text"
      },
      "source": [
        "### 2. Binary Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0UFUc8huMbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"data/sen_imdb/train.csv\")\n",
        "test = pd.read_csv(\"data/sen_imdb/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT9B1WmFuMbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_texts, train_labels = list(train.text), list(train.pos)\n",
        "test_texts, test_labels = list(test.text), list(test.pos)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTkeuE4WuMbx",
        "colab_type": "text"
      },
      "source": [
        "#### ASCII"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CrPYE_ZuMby",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "b17e7a7e-c1e2-4c68-f4be-31a13e23e697"
      },
      "source": [
        "model = LogisticRegression(random_state=0, solver='liblinear')\n",
        "for method in [\"mean\", \"first\"]:\n",
        "    print(f\"Agg method: {method}\")\n",
        "    vectorizer = ASCIIVectorizer(max_features=128, char_aggregator=method)\n",
        "    \n",
        "    X_train, y_train = vectorizer.transform(train_texts, train_labels)\n",
        "    X_test, y_test = vectorizer.transform(test_texts, test_labels)\n",
        "    \n",
        "    # Fit the model to training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make prediction using the trained model\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate\n",
        "    train_acc = accuracy_score(y_train, y_train_pred)\n",
        "    train_prec = precision_score(y_train, y_train_pred)\n",
        "    train_rec = recall_score(y_train, y_train_pred)\n",
        "    train_f1 = f1_score(y_train, y_train_pred)\n",
        "    \n",
        "    test_acc = accuracy_score(y_test, y_test_pred)\n",
        "    test_prec = precision_score(y_test, y_test_pred)\n",
        "    test_rec = recall_score(y_test, y_test_pred)\n",
        "    test_f1 = f1_score(y_test, y_test_pred)\n",
        "    \n",
        "    print(f\"Training accuracy: {train_acc:.3f}, \"\n",
        "          f\"Precison: {train_prec:.3f}, \"\n",
        "          f\"Recall: {train_rec:.3f}, \"\n",
        "          f\"F1 score: {train_f1:.3f}\")\n",
        "    print(f\"Test accuracy: {test_acc:.3f}, \"\n",
        "          f\"Precison: {test_prec:.3f}, \"\n",
        "          f\"Recall: {test_rec:.3f}, \"\n",
        "          f\"F1 score: {test_f1:.3f}\\n\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Agg method: mean\n",
            "Training accuracy: 0.538, Precison: 0.538, Recall: 0.540, F1 score: 0.539\n",
            "Test accuracy: 0.513, Precison: 0.513, Recall: 0.516, F1 score: 0.514\n",
            "\n",
            "Agg method: first\n",
            "Training accuracy: 0.535, Precison: 0.538, Recall: 0.494, F1 score: 0.515\n",
            "Test accuracy: 0.511, Precison: 0.512, Recall: 0.475, F1 score: 0.493\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4kYk_N5uMb0",
        "colab_type": "text"
      },
      "source": [
        "#### BoW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmyj7aXsuMb0",
        "colab_type": "code",
        "colab": {},
        "outputId": "a2bce565-bcdb-4701-b20b-7b26d2dfea1f"
      },
      "source": [
        "model = LogisticRegression(random_state=0, solver='liblinear')\n",
        "for nf in [8, 16, 32, 64, 128, 256, 512, 1024, 2048]:\n",
        "    print(f\"Vocab size: {nf}\")\n",
        "    \n",
        "    vectorizer = BoWVectorizer(max_features=nf)\n",
        "    vectorizer.fit(train_texts)\n",
        "    \n",
        "    X_train, y_train = vectorizer.transform(train_texts, train_labels)\n",
        "    X_test, y_test = vectorizer.transform(test_texts, test_labels)\n",
        "\n",
        "    # Fit the model to training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make prediction using the trained model\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate\n",
        "    train_acc = accuracy_score(y_train, y_train_pred)\n",
        "    train_prec = precision_score(y_train, y_train_pred)\n",
        "    train_rec = recall_score(y_train, y_train_pred)\n",
        "    train_f1 = f1_score(y_train, y_train_pred)\n",
        "    \n",
        "    test_acc = accuracy_score(y_test, y_test_pred)\n",
        "    test_prec = precision_score(y_test, y_test_pred)\n",
        "    test_rec = recall_score(y_test, y_test_pred)\n",
        "    test_f1 = f1_score(y_test, y_test_pred)\n",
        "    \n",
        "    print(f\"Training accuracy: {train_acc:.3f}, \"\n",
        "          f\"Precison: {train_prec:.3f}, \"\n",
        "          f\"Recall: {train_rec:.3f}, \"\n",
        "          f\"F1 score: {train_f1:.3f}\")\n",
        "    print(f\"Test accuracy: {test_acc:.3f}, \"\n",
        "          f\"Precison: {test_prec:.3f}, \"\n",
        "          f\"Recall: {test_rec:.3f}, \"\n",
        "          f\"F1 score: {test_f1:.3f}\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 8\n",
            "Training accuracy: 0.581, Precison: 0.586, Recall: 0.554, F1 score: 0.569\n",
            "Test accuracy: 0.579, Precison: 0.584, Recall: 0.553, F1 score: 0.568\n",
            "\n",
            "Vocab size: 16\n",
            "Training accuracy: 0.612, Precison: 0.610, Recall: 0.619, F1 score: 0.615\n",
            "Test accuracy: 0.612, Precison: 0.610, Recall: 0.619, F1 score: 0.614\n",
            "\n",
            "Vocab size: 32\n",
            "Training accuracy: 0.628, Precison: 0.625, Recall: 0.641, F1 score: 0.633\n",
            "Test accuracy: 0.627, Precison: 0.624, Recall: 0.638, F1 score: 0.631\n",
            "\n",
            "Vocab size: 64\n",
            "Training accuracy: 0.681, Precison: 0.673, Recall: 0.704, F1 score: 0.688\n",
            "Test accuracy: 0.675, Precison: 0.669, Recall: 0.694, F1 score: 0.681\n",
            "\n",
            "Vocab size: 128\n",
            "Training accuracy: 0.756, Precison: 0.747, Recall: 0.773, F1 score: 0.760\n",
            "Test accuracy: 0.746, Precison: 0.739, Recall: 0.761, F1 score: 0.750\n",
            "\n",
            "Vocab size: 256\n",
            "Training accuracy: 0.797, Precison: 0.787, Recall: 0.815, F1 score: 0.800\n",
            "Test accuracy: 0.787, Precison: 0.778, Recall: 0.803, F1 score: 0.790\n",
            "\n",
            "Vocab size: 512\n",
            "Training accuracy: 0.846, Precison: 0.838, Recall: 0.858, F1 score: 0.848\n",
            "Test accuracy: 0.840, Precison: 0.830, Recall: 0.856, F1 score: 0.843\n",
            "\n",
            "Vocab size: 1024\n",
            "Training accuracy: 0.873, Precison: 0.865, Recall: 0.884, F1 score: 0.874\n",
            "Test accuracy: 0.862, Precison: 0.853, Recall: 0.874, F1 score: 0.863\n",
            "\n",
            "Vocab size: 2048\n",
            "Training accuracy: 0.889, Precison: 0.882, Recall: 0.899, F1 score: 0.890\n",
            "Test accuracy: 0.872, Precison: 0.866, Recall: 0.881, F1 score: 0.873\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFyzruHwuMb2",
        "colab_type": "text"
      },
      "source": [
        "#### BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NJxdDSZuMb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "83dc730d-1ff2-46e2-8b09-6737376a9a19"
      },
      "source": [
        "model = LogisticRegression(random_state=0, solver='liblinear')\n",
        "for vs in [10, 20, 50, 100, 200, 500, 1000, 2000]:    \n",
        "    vectorizer = BiLSTMVectorizer(vocab_size=vs)\n",
        "\n",
        "    #if vs >= 200:\n",
        "    #  bsize = 32\n",
        "    #else:\n",
        "    #  bsize = 64\n",
        "    \n",
        "    X_train, y_train = vectorizer.transform(train_texts, train_labels, 32)\n",
        "    X_test, y_test = vectorizer.transform(test_texts, test_labels, 32)\n",
        "\n",
        "    # Fit the model to training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make prediction using the trained model\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate\n",
        "    train_acc = accuracy_score(y_train, y_train_pred)\n",
        "    train_prec = precision_score(y_train, y_train_pred)\n",
        "    train_rec = recall_score(y_train, y_train_pred)\n",
        "    train_f1 = f1_score(y_train, y_train_pred)\n",
        "    \n",
        "    test_acc = accuracy_score(y_test, y_test_pred)\n",
        "    test_prec = precision_score(y_test, y_test_pred)\n",
        "    test_rec = recall_score(y_test, y_test_pred)\n",
        "    test_f1 = f1_score(y_test, y_test_pred)\n",
        "    \n",
        "    print(f\"Training accuracy: {train_acc:.3f}, \"\n",
        "          f\"Precison: {train_prec:.3f}, \"\n",
        "          f\"Recall: {train_rec:.3f}, \"\n",
        "          f\"F1 score: {train_f1:.3f}\")\n",
        "    print(f\"Test accuracy: {test_acc:.3f}, \"\n",
        "          f\"Precison: {test_prec:.3f}, \"\n",
        "          f\"Recall: {test_rec:.3f}, \"\n",
        "          f\"F1 score: {test_f1:.3f}\\n\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size : 10\n",
            "Training accuracy: 0.648, Precison: 0.649, Recall: 0.647, F1 score: 0.648\n",
            "Test accuracy: 0.607, Precison: 0.605, Recall: 0.612, F1 score: 0.609\n",
            "\n",
            "Vocab size : 20\n",
            "Training accuracy: 0.674, Precison: 0.675, Recall: 0.671, F1 score: 0.673\n",
            "Test accuracy: 0.623, Precison: 0.623, Recall: 0.622, F1 score: 0.623\n",
            "\n",
            "Vocab size : 50\n",
            "Training accuracy: 0.744, Precison: 0.740, Recall: 0.753, F1 score: 0.746\n",
            "Test accuracy: 0.694, Precison: 0.691, Recall: 0.703, F1 score: 0.697\n",
            "\n",
            "Vocab size : 100\n",
            "Training accuracy: 0.774, Precison: 0.769, Recall: 0.781, F1 score: 0.775\n",
            "Test accuracy: 0.722, Precison: 0.720, Recall: 0.729, F1 score: 0.724\n",
            "\n",
            "Vocab size : 200\n",
            "Training accuracy: 0.805, Precison: 0.805, Recall: 0.804, F1 score: 0.805\n",
            "Test accuracy: 0.765, Precison: 0.767, Recall: 0.761, F1 score: 0.764\n",
            "\n",
            "Vocab size : 500\n",
            "Training accuracy: 0.834, Precison: 0.832, Recall: 0.837, F1 score: 0.835\n",
            "Test accuracy: 0.790, Precison: 0.788, Recall: 0.795, F1 score: 0.791\n",
            "\n",
            "Vocab size : 1000\n",
            "Training accuracy: 0.851, Precison: 0.849, Recall: 0.853, F1 score: 0.851\n",
            "Test accuracy: 0.802, Precison: 0.803, Recall: 0.801, F1 score: 0.802\n",
            "\n",
            "Vocab size : 2000\n",
            "Training accuracy: 0.862, Precison: 0.863, Recall: 0.861, F1 score: 0.862\n",
            "Test accuracy: 0.816, Precison: 0.816, Recall: 0.815, F1 score: 0.816\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWnUnQATGoOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "baseline_tests.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}